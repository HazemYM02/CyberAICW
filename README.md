# FaceGuard: AI-Based Access Control with Adversarial Testing

This project presents a complete pipeline for building, evaluating, attacking, and defending an AI-based facial recognition system called FaceGuard, inspired by real-world access control use cases in cybersecurity.

It includes:
	â€¢	A CNN for face recognition using the Extended Olivetti Faces dataset.
	â€¢	A function for access control (Access_Control) granting or denying entry to specific individuals.
	â€¢	Adversarial robustness evaluation using FGSM attacks (targeted & untargeted).
	â€¢	Defense via adversarial training.

â¸»

Features
	â€¢	ğŸ§  Face Recognition CNN
Custom CNN trained to classify 40 individuals using grayscale face images (64Ã—64).
	â€¢	ğŸ” Access Control System
Implements logic to only grant access to authorized personnel (IDs 0, 5, and 10).
	â€¢	ğŸ§ª Adversarial Testing
	â€¢	Untargeted FGSM Attack: Evaluates model robustness against increasing Îµ (epsilon) values.
	â€¢	Targeted FGSM Attack: Forces misclassification to gain unauthorized access.
	â€¢	ğŸ›¡ Adversarial Training (Blue Team)
Retrains model using adversarial examples to improve resistance to attacks.

â¸»

ğŸ›  Installation

ğŸ”§ Requirements

pip install torch torchvision numpy matplotlib scikit-learn pillow


â¸»

ğŸš€ How to Run
	1.	Launch the notebook:

jupyter notebook CW.ipynb


	2.	Run through the sections:
	â€¢	CNN Definition & Training
	â€¢	Model Evaluation
	â€¢	Access Control Logic
	â€¢	FGSM Attacks (Targeted & Untargeted)
	â€¢	Adversarial Training and Comparison

â¸»

ğŸ“Š Sample Results
	â€¢	Accuracy Plot: Model performance over training epochs.
	â€¢	Access Logs: Console output of â€œAccess Grantedâ€ or â€œAccess Deniedâ€.
	â€¢	Adversarial Visuals: Comparison between original and perturbed inputs.
	â€¢	Epsilon vs Accuracy: Visualization of model robustness under FGSM.

â¸»

ğŸ” Use Case

This project simulates a real-world cybersecurity scenario: securing access to a sensitive area using AI and understanding its vulnerabilities through red team (attack) and blue team (defense) strategies.

â¸»
